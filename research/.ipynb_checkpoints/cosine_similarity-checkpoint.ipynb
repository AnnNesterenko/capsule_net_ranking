{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import codecs\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(first, second):\n",
    "    return metrics.pairwise.cosine_similarity(first.reshape(1, -1), second.reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/annanesterenko/Desktop/diplom_final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARXIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quality(embeddings_file, triples_file=f\"{path}/data/ARXIV/arxiv_triplets.txt\", func=cos_sim):\n",
    "    all_triplets = 0\n",
    "    covered_triplets = 0\n",
    "    correct_triplets = 0\n",
    "    \n",
    "    embeddings = []\n",
    "    id2tag = {}\n",
    "    with codecs.open(embeddings_file) as f:\n",
    "        for line in f:\n",
    "            id_, embedding = line.split(' ', maxsplit=1)\n",
    "            id2tag[id_[2:]] = len(embeddings)\n",
    "            embeddings.append(embedding)\n",
    "\n",
    "    with codecs.open(triples_file) as fin:\n",
    "        for line in fin:\n",
    "            id1, id2, id3 = map(lambda x: x.split('/pdf/')[-1], line.split())\n",
    "            if id1 in id2tag and id2 in id2tag and id3 in id2tag:\n",
    "                covered_triplets += 1\n",
    "                t1, t2, t3 = id2tag[id1], id2tag[id2], id2tag[id3]\n",
    "                query = np.array(list(map(float, embeddings[t1].split())))\n",
    "                good_req = np.array(list(map(float, embeddings[t2].split())))\n",
    "                bad_req = np.array(list(map(float, embeddings[t3].split())))\n",
    "                correct_triplets += func(query, good_req) > cos_sim(query, bad_req)\n",
    "            all_triplets += 1\n",
    "    return 1.0 * correct_triplets / covered_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7862865072856873"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(f\"{path}/data/ARXIV/embeddings_doc2vec.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8546900643858099"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(\"data/embeddings_fasttext.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CapsE.prepare_ import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quality(lst_embeddings_query, \n",
    "                     lst_embeddings_doc, \n",
    "                     test_duplets,\n",
    "                     test_val_duplets,\n",
    "                     func=cos_sim):\n",
    "    \n",
    "    all_triplets = len(test_duplets)\n",
    "    recall = 0\n",
    "    recall1 = 0\n",
    "    recall2 = 0\n",
    "    recall3 = 0\n",
    "    precision = 0\n",
    "    \n",
    "    for i in range(len(test_duplets)):\n",
    "        ranked = []\n",
    "        query = lst_embeddings_query[test_duplets[i][0][0]] \n",
    "\n",
    "        relevant_cnt = 0\n",
    "        for j in range(10):\n",
    "            ans = lst_embeddings_doc[test_duplets[i][j][1]]\n",
    "            cos_sim = func(query, ans)\n",
    "            \n",
    "            ranked.append([cos_sim, test_val_duplets[i][j][0]])\n",
    "            relevant_cnt += test_val_duplets[i][j][0]\n",
    "            \n",
    "        ranked.sort(key=lambda x: x[0], reverse=True)\n",
    "        ranked_relevance = [i[1] for i in ranked]\n",
    "        \n",
    "        precision += sum(ranked_relevance[:relevant_cnt]) / relevant_cnt\n",
    "        recall += (sum(ranked_relevance[:relevant_cnt]) == relevant_cnt)\n",
    "        recall1 += (ranked_relevance[0] == 1)\n",
    "        recall2 += (sum(ranked_relevance[:2]) == 2)\n",
    "        recall3 += (sum(ranked_relevance[:3]) == 3)\n",
    "        \n",
    "    return recall / all_triplets, precision / all_triplets, recall1 / all_triplets, recall2 / all_triplets, recall3 / all_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_embeddings_query, lst_embeddings_doc, \\\n",
    "           train_duplets, test_duplets, \\\n",
    "           train_val_duplets, test_val_duplets = get_data_for_net_MIND(\n",
    "                                        embeddings_file_train=f'{path}/data/MIND/embeddings_doc2vec_train.txt', \n",
    "                                        embeddings_file_test=f'{path}/data/MIND/embeddings_doc2vec_test.txt',\n",
    "                                        behaviors_train=f'{path}/data/MIND/behaviors_train.tsv',\n",
    "                                        behaviors_test=f'{path}/data/MIND/behaviors_test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.018166666666666668,\n",
       " 0.4531222222222235,\n",
       " 0.47733333333333333,\n",
       " 0.208,\n",
       " 0.08916666666666667)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(lst_embeddings_query, \n",
    "                     lst_embeddings_doc, \n",
    "                     test_duplets,\n",
    "                     test_val_duplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_embeddings_query, lst_embeddings_doc, \\\n",
    "           train_duplets, test_duplets, \\\n",
    "           train_val_duplets, test_val_duplets = get_data_for_net_MIND(\n",
    "                                        embeddings_file_train=f'{path}/data/MIND/embeddings_fasttext_train.txt', \n",
    "                                        embeddings_file_test=f'{path}/data/MIND/embeddings_fasttext_test.txt',\n",
    "                                        behaviors_train=f'{path}/data/MIND/behaviors_train.tsv',\n",
    "                                        behaviors_test=f'{path}/data/MIND/behaviors_test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.019333333333333334,\n",
       " 0.44795476190476236,\n",
       " 0.46316666666666667,\n",
       " 0.20066666666666666,\n",
       " 0.0825)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(lst_embeddings_query, \n",
    "                     lst_embeddings_doc, \n",
    "                     test_duplets,\n",
    "                     test_val_duplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_embeddings_query, lst_embeddings_doc, \\\n",
    "           train_duplets, test_duplets, \\\n",
    "           train_val_duplets, test_val_duplets = get_data_for_net_MIND(\n",
    "                                        embeddings_file_train=f'{path}/data/MIND/embeddings_BERT_train.txt', \n",
    "                                        embeddings_file_test=f'{path}/data/MIND/embeddings_BERT_test.txt',\n",
    "                                        behaviors_train=f'{path}/data/MIND/behaviors_train.tsv',\n",
    "                                        behaviors_test=f'{path}/data/MIND/behaviors_test.tsv', \n",
    "                                        SIZE=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02266666666666667,\n",
       " 0.42035912698412753,\n",
       " 0.45666666666666667,\n",
       " 0.1885,\n",
       " 0.06716666666666667)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(lst_embeddings_query, \n",
    "                     lst_embeddings_doc, \n",
    "                     test_duplets,\n",
    "                     test_val_duplets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
