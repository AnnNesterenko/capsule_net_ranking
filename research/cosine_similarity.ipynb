{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import codecs\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(first, second):\n",
    "    return metrics.pairwise.cosine_similarity(first.reshape(1, -1), second.reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/annanesterenko/Desktop/diplom_final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARXIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quality(embeddings_file, triples_file=f\"{path}/data/ARXIV/arxiv_triplets.txt\", func=cos_sim):\n",
    "    all_triplets = 0\n",
    "    covered_triplets = 0\n",
    "    correct_triplets = 0\n",
    "    \n",
    "    embeddings = []\n",
    "    id2tag = {}\n",
    "    with codecs.open(embeddings_file) as f:\n",
    "        for line in f:\n",
    "            id_, embedding = line.split(' ', maxsplit=1)\n",
    "            id2tag[id_[2:]] = len(embeddings)\n",
    "            embeddings.append(embedding)\n",
    "\n",
    "    with codecs.open(triples_file) as fin:\n",
    "        for line in fin:\n",
    "            id1, id2, id3 = map(lambda x: x.split('/pdf/')[-1], line.split())\n",
    "            if id1 in id2tag and id2 in id2tag and id3 in id2tag:\n",
    "                covered_triplets += 1\n",
    "                t1, t2, t3 = id2tag[id1], id2tag[id2], id2tag[id3]\n",
    "                query = np.array(list(map(float, embeddings[t1].split())))\n",
    "                good_req = np.array(list(map(float, embeddings[t2].split())))\n",
    "                bad_req = np.array(list(map(float, embeddings[t3].split())))\n",
    "                correct_triplets += func(query, good_req) > cos_sim(query, bad_req)\n",
    "            all_triplets += 1\n",
    "    return 1.0 * correct_triplets / covered_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7862865072856873"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(f\"{path}/data/ARXIV/embeddings_doc2vec.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8546900643858099"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(\"data/embeddings_fasttext.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CapsE.prepare_3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quality(lst_embeddings_query, \n",
    "                     lst_embeddings_doc, \n",
    "                     test_duplets,\n",
    "                     test_val_duplets,\n",
    "                     func=cos_sim):\n",
    "    \n",
    "    all_triplets = len(test_duplets)\n",
    "    recall = 0\n",
    "    recall1 = 0\n",
    "    recall2 = 0\n",
    "    recall3 = 0\n",
    "    precision = 0\n",
    "    \n",
    "    ndcg3 = 0\n",
    "    ndcg5 = 0\n",
    "    ndcg10 = 0\n",
    "    \n",
    "    for i in range(len(test_duplets)):\n",
    "        ranked = []\n",
    "        query = lst_embeddings_query[test_duplets[i][0][0]] \n",
    "\n",
    "        relevant_cnt = 0\n",
    "        for j in range(10):\n",
    "            ans = lst_embeddings_doc[test_duplets[i][j][1]]\n",
    "            cos_sim = func(query, ans)\n",
    "            \n",
    "            ranked.append([cos_sim, test_val_duplets[i][j][0]])\n",
    "            relevant_cnt += test_val_duplets[i][j][0]\n",
    "            \n",
    "        ranked.sort(key=lambda x: x[0], reverse=True)\n",
    "        ranked_relevance = [i[1] for i in ranked]\n",
    "        \n",
    "        precision += sum(ranked_relevance[:relevant_cnt]) / relevant_cnt\n",
    "        recall += (sum(ranked_relevance[:relevant_cnt]) == relevant_cnt)\n",
    "        recall1 += (ranked_relevance[0] == 1)\n",
    "        recall2 += (sum(ranked_relevance[:2]) == 2)\n",
    "        recall3 += (sum(ranked_relevance[:3]) == 3)\n",
    "        \n",
    "        #ndcg@3\n",
    "        ndcg3 += sum([ranked_relevance[k-1] / np.log2(k+1) for k in range(1, 3)]) \\\n",
    "            / sum([1/np.log2(k+1) for k in range(1, 6)])\n",
    "        #ndcg@5\n",
    "        ndcg5 += sum([ranked_relevance[k-1] / np.log2(k+1) for k in range(1, 6)]) \\\n",
    "            / sum([1/np.log2(k+1) for k in range(1, 6)])\n",
    "        #ndcg@10\n",
    "        ndcg10 += sum([ranked_relevance[k-1] / np.log2(k+1) for k in range(1, 11)]) \\\n",
    "            / sum([1/np.log2(k+1) for k in range(1, 6)])\n",
    "        \n",
    "    return recall / all_triplets, precision / all_triplets, recall1 / all_triplets, \\\n",
    "            recall2 / all_triplets, recall3 / all_triplets, ndcg3 / all_triplets, \\\n",
    "            ndcg5 / all_triplets, ndcg10 / all_triplets,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_embeddings_query, lst_embeddings_doc, \\\n",
    "           train_duplets, test_duplets, \\\n",
    "           train_val_duplets, test_val_duplets = get_data_for_net_MIND(\n",
    "                                        embeddings_file_train=f'{path}/data/MIND/embeddings_doc2vec_train.txt', \n",
    "                                        embeddings_file_test=f'{path}/data/MIND/embeddings_doc2vec_test.txt',\n",
    "                                        behaviors_train=f'{path}/data/MIND/behaviors_train.tsv',\n",
    "                                        behaviors_test=f'{path}/data/MIND/behaviors_test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44908, 200)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_embeddings_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34677, 11556],\n",
       "       [34677,   918],\n",
       "       [34677, 12260],\n",
       "       [34677,  3151],\n",
       "       [34677,  1299],\n",
       "       [34677, 12518],\n",
       "       [34677,  2180],\n",
       "       [34677,  8609],\n",
       "       [34677,  5096],\n",
       "       [34677,  4491]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_duplets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_duplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.016166666666666666,\n",
       " 0.4498440476190485,\n",
       " 0.4633333333333333,\n",
       " 0.201,\n",
       " 0.08166666666666667,\n",
       " 0.25621986901554084,\n",
       " 0.44641964276891666,\n",
       " 0.6332252710803599)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(lst_embeddings_query, \n",
    "                     lst_embeddings_doc, \n",
    "                     test_duplets,\n",
    "                     test_val_duplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_embeddings_query, lst_embeddings_doc, \\\n",
    "           train_duplets, test_duplets, \\\n",
    "           train_val_duplets, test_val_duplets = get_data_for_net_MIND(\n",
    "                                        embeddings_file_train=f'{path}/data/MIND/embeddings_fasttext_train.txt', \n",
    "                                        embeddings_file_test=f'{path}/data/MIND/embeddings_fasttext_test.txt',\n",
    "                                        behaviors_train=f'{path}/data/MIND/behaviors_train.tsv',\n",
    "                                        behaviors_test=f'{path}/data/MIND/behaviors_test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.019666666666666666,\n",
       " 0.4446186507936511,\n",
       " 0.4525,\n",
       " 0.19566666666666666,\n",
       " 0.08133333333333333,\n",
       " 0.2512617158700025,\n",
       " 0.4405059394615861,\n",
       " 0.6299780387146978)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(lst_embeddings_query, \n",
    "                     lst_embeddings_doc, \n",
    "                     test_duplets,\n",
    "                     test_val_duplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_embeddings_query, lst_embeddings_doc, \\\n",
    "           train_duplets, test_duplets, \\\n",
    "           train_val_duplets, test_val_duplets = get_data_for_net_MIND(\n",
    "                                        embeddings_file_train=f'{path}/data/MIND/embeddings_BERT_train.txt', \n",
    "                                        embeddings_file_test=f'{path}/data/MIND/embeddings_BERT_test.txt',\n",
    "                                        behaviors_train=f'{path}/data/MIND/behaviors_train.tsv',\n",
    "                                        behaviors_test=f'{path}/data/MIND/behaviors_test.tsv', \n",
    "                                        SIZE=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.024666666666666667,\n",
       " 0.42286111111111174,\n",
       " 0.4698333333333333,\n",
       " 0.19716666666666666,\n",
       " 0.08116666666666666,\n",
       " 0.2509705554615659,\n",
       " 0.4222677848005323,\n",
       " 0.5938811566894348)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_quality(lst_embeddings_query, \n",
    "                     lst_embeddings_doc, \n",
    "                     test_duplets,\n",
    "                     test_val_duplets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
